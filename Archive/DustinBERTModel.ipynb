{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45surhmEZ2-H"
      },
      "outputs": [],
      "source": [
        "# # Need to tap local runtime resources\n",
        "# !pip install jupyterlab\n",
        "# !pip install jupyter_http_over_ws\n",
        "# !jupyter serverextension enable --py jupyter_http_over_ws"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YjmX9yWSRu-",
        "outputId": "11c081c8-898a-4967-ebdf-f1b1e9384a12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 15.9 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 90.1 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 95.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n",
            "Cloning into 'W266_Group_Project'...\n",
            "remote: Enumerating objects: 164, done.\u001b[K\n",
            "remote: Counting objects: 100% (164/164), done.\u001b[K\n",
            "remote: Compressing objects: 100% (151/151), done.\u001b[K\n",
            "remote: Total 164 (delta 65), reused 51 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (164/164), 136.69 MiB | 18.72 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Checking out files: 100% (34/34), done.\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 15.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 94.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 96.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
            "\u001b[K     |████████████████████████████████| 134 kB 92.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 100.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 96.5 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 84.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.0.0 frozenlist-1.3.0 fsspec-2022.2.0 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "# Setup for Google Colab\n",
        "#!pip install tensorflow-gpu\n",
        "!pip install transformers\n",
        "!git clone https://github.com/CodyBurker/W266_Group_Project\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h8jdCX2UCGF",
        "outputId": "e4c54b9a-ec01-4133-ff1d-26b4cf0717e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Mar 27 15:05:47 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l52ZY3KWjMPK"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, TFBertModel, TFBertForSequenceClassification\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BV98hg0SexQ"
      },
      "outputs": [],
      "source": [
        "# def read_in_data(path=\"W266_Group_Project/\"):\n",
        "#     import pandas as pd\n",
        "#     X_train = pd.read_csv(path + \"x_train_sampled_yelp_data.csv\")\n",
        "#     y_train = pd.read_csv(path + \"y_train_sampled_yelp_data.csv\")\n",
        "#     X_test = pd.read_csv(path + \"x_test_sampled_yelp_data.csv\")\n",
        "#     y_test = pd.read_csv(path + \"y_test_sampled_yelp_data.csv\")\n",
        "#     return X_train, X_test, y_train, y_test\n",
        "# X_train, X_test, y_train, y_test = read_in_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "LllM6Jmj5n5d"
      },
      "outputs": [],
      "source": [
        "def read_in_data(path=\"W266_Group_Project/\"):\n",
        "    import pandas as pd\n",
        "    X_train = pd.read_csv(path + \"x_train_stage_1_sampled_yelp_data.csv\")\n",
        "    y_train = pd.read_csv(path + \"y_train_stage_1_sampled_yelp_data.csv\")\n",
        "    X_test = pd.read_csv(path + \"x_test_sampled_yelp_data_NEW.csv\")\n",
        "    y_test = pd.read_csv(path + \"y_test_sampled_yelp_data_NEW.csv\")\n",
        "    X_train_stage_2 = pd.read_csv(path + \"x_train_stage_2_sampled_yelp_data.csv\")\n",
        "    y_train_stage_2 = pd.read_csv(path + \"y_train_stage_2_sampled_yelp_data.csv\")\n",
        "    return X_train, X_test, y_train, y_test, X_train_stage_2, y_train_stage_2\n",
        "X_train, X_test, y_train, y_test, X_train_stage_2, y_train_stage_2 = read_in_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "NSwJgj02VAWn",
        "outputId": "2c7e93c0-25af-45b5-e489-b63e1f75e52a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Only been here once and the vegan horchata peanut butter ice cream SLAPSSSS. So good you will wish you got an extra large and not a tiny. I think I could eat that every single day. It was delicious and I have no complaints about it other than the price. It was like $5 for 2 scoops of ice cream. Yikes. Regardless, so good! Would highly recommend.'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train['text'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKMPbHMNVSv2"
      },
      "outputs": [],
      "source": [
        "y_train['stars'] = y_train['stars'] - 1\n",
        "y_test['stars'] = y_test['stars'] - 1\n",
        "# shifting predicted categories down by 1 to work in the sparse_cateforial_entropy loss below "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xHzbjruXTWR",
        "outputId": "ba91e06d-d8dd-49e2-c297-f075794be02f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        4.0\n",
              "1        4.0\n",
              "2        4.0\n",
              "3        2.0\n",
              "4        4.0\n",
              "        ... \n",
              "79995    4.0\n",
              "79996    4.0\n",
              "79997    3.0\n",
              "79998    3.0\n",
              "79999    4.0\n",
              "Name: stars, Length: 80000, dtype: float64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train['stars']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrGTZJDoINB4"
      },
      "outputs": [],
      "source": [
        "# Exploring options from https://towardsdatascience.com/sentiment-analysis-in-10-minutes-with-bert-and-hugging-face-294e8a04b671\n",
        "# from transformers import TFBertForSequenceClassification\n",
        "# ?TFBertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVcrNh9ji8D7"
      },
      "outputs": [],
      "source": [
        "#from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "#import tensorflow as tf\n",
        "\n",
        "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "#model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "#inputs = tokenizer(\"Hello, my dog is ugly, mean, and bad\", return_tensors=\"tf\")\n",
        "#inputs[\"labels\"] = tf.reshape(tf.constant(1), (-1, 1))  # Batch size 1\n",
        "\n",
        "#outputs = model(inputs)\n",
        "#loss = outputs.loss\n",
        "#logits = outputs.logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDdYKFe-E0p2"
      },
      "outputs": [],
      "source": [
        "# Look at the layers in the BERT base model\n",
        "#[i.name for i in model.weights]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wKZxl0LPLNa"
      },
      "outputs": [],
      "source": [
        "# def how_many_tokens(input_examples, tokenizer=tokenizer,\n",
        "#                     quantiles = [0, .25, .5, .75, 1]):\n",
        "#   \"\"\" \n",
        "#   Determine the desired quantiles calculated from the length (in token IDs) of \n",
        "#   provided text examples using a desired tokenizer.\n",
        "  \n",
        "#   Input: list of examples\n",
        "\n",
        "#   Output: Number of token IDs at quantiles in any of the given input examples \n",
        "#   (excluding special token IDs such as CLS, UNK, SEP) \n",
        "#   \"\"\" \n",
        "\n",
        "#   input_token_id_lengths = []\n",
        "#   for i in input_examples:\n",
        "#     tokens = tokenizer.tokenize(i)\n",
        "#     token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "#     input_token_id_lengths.append(len(token_ids))\n",
        "\n",
        "#   return np.quantile(input_token_id_lengths, quantiles), input_token_id_lengths\n",
        "\n",
        "# # The results of running this function on the training text examples (100K) was\n",
        "# # 4,406 max token IDs - pretty long - and the below quantiles:\n",
        "# # array([1.000e+00, 5.600e+01, 1.010e+02, 1.780e+02, 4.406e+03])\n",
        "# # how_many_tokens(X_train['text'])\n",
        "\n",
        "# # The results for below, same run on test examples yielded: \n",
        "# # array([   2.,   56.,  100.,  178., 1385.])\n",
        "# # how_many_tokens(X_test['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvKlstgnrNMy"
      },
      "outputs": [],
      "source": [
        "# While the max length is 4,406, only 2.2% of examples would be truncated if\n",
        "# we set the max length at 512 (for padding purposes), as seen below\n",
        "# quantiles, token_lengths = how_many_tokens(X_train['text'])\n",
        "# print(quantiles)\n",
        "# print('Proportion of examples > 512 tokens:', (np.sum(np.array(token_lengths)>512)/(len(token_lengths))))\n",
        "\n",
        "# Setting max length based on above\n",
        "# max_length = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_S_Q4u_4j9uD"
      },
      "outputs": [],
      "source": [
        "# def examples_to_BERT_inputs(input_examples, input_labels, tokenizer=tokenizer, \n",
        "#                             max_length=max_length):\n",
        "#   #c= 0\n",
        "#   input_ids = []\n",
        "#   attention_mask = []\n",
        "#   #labels = []\n",
        "\n",
        "#   for i in input_examples:\n",
        "#     encoding = tokenizer.encode_plus(\n",
        "#         i,\n",
        "#         truncation = True, \n",
        "#         add_special_tokens = True,\n",
        "#         padding = 'max_length',\n",
        "#         return_attention_mask = True#,\n",
        "#         #return_tensors='tf'\n",
        "#     )\n",
        "\n",
        "#     input_ids.append(encoding['input_ids'])\n",
        "#     attention_mask.append(encoding['attention_mask'])\n",
        "#     #labels.append(input_labels[c])\n",
        "\n",
        "#     #c+=1\n",
        "\n",
        "#   return {'input_ids': input_ids, 'attention_mask': attention_mask}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjbVDGf6Gj0A"
      },
      "outputs": [],
      "source": [
        "# Check to see if the base model is performing as expected\n",
        "# results_base = model(examples_to_BERT_inputs(X_train['text'][:100], y_train['stars'][:100]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9SppiJWG6KP"
      },
      "outputs": [],
      "source": [
        "# results_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mf2vDeMDwT3v"
      },
      "outputs": [],
      "source": [
        "#Look at the shape of every layer in the pretrained model\n",
        "#for layer in range(len(bert.layers[0].weights))[:10]:\n",
        "    #print(layer)\n",
        "    #print('Layer name: \\t', bert.layers[0].weights[layer].name)\n",
        "    #print('Layer shape: \\t', bert.layers[0].weights[layer].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKNL610WoCrS"
      },
      "outputs": [],
      "source": [
        "# tokenizer.tokenize('Testing to see how this BERT tokenizer splits various kinds of words, sometimes unusually')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZayxKUGEpiSM"
      },
      "outputs": [],
      "source": [
        "# tokenizer.convert_tokens_to_ids([\n",
        "#                                  '[CLS]', \n",
        "#                                  'Testing',\n",
        "#                                  'to',\n",
        "#                                  'see',\n",
        "#                                  'how',\n",
        "#                                  'this', \n",
        "#                                  'works', \n",
        "#                                  '[SEP]'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4LYUokIpsFj"
      },
      "outputs": [],
      "source": [
        "# tokenizer.convert_ids_to_tokens([101])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLJ9gvujrESq"
      },
      "outputs": [],
      "source": [
        "#Establish bare base pretrained BERT model, and see layers\n",
        "# bert = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "# note the model name / path is a string - the *model id* of a pretrained model \n",
        "# hosted inside a model repo on huggingface.co"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGVv42Oyrk26"
      },
      "outputs": [],
      "source": [
        "#curious to see example weights at the first layer\n",
        "# bert.layers[0].weights[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1jtEBclMpHr"
      },
      "outputs": [],
      "source": [
        "# Resource used to guide work: \n",
        "# https://raviteja-ganta.github.io/sentiment-analysis-using-bert-and-hugging-face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouuCWx0tjJxT"
      },
      "outputs": [],
      "source": [
        "# outputs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqKozcegaAYN"
      },
      "outputs": [],
      "source": [
        "# train['DATA_COLUMN'] = pd.DataFrame(X_train['text'])\n",
        "# train['LABEL_COLUMN'] = y_train['stars']\n",
        "# test['DATA_COLUMN'] = pd.DataFrame(X_test['text'])\n",
        "# test['LABEL_COLUMN'] = y_test['stars']\n",
        "\n",
        "# #pd.DataFrame(test[['text', 'stars']])\n",
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vocYmMv1UNv3"
      },
      "outputs": [],
      "source": [
        "# def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN): \n",
        "#   train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
        "#                                                           text_a = x[DATA_COLUMN], \n",
        "#                                                           text_b = None,\n",
        "#                                                           label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "#   validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
        "#                                                           text_a = x[DATA_COLUMN], \n",
        "#                                                           text_b = None,\n",
        "#                                                           label = x[LABEL_COLUMN]), axis = 1)\n",
        "  \n",
        "#   return train_InputExamples, validation_InputExamples\n",
        "\n",
        "#   train_InputExamples, validation_InputExamples = convert_data_to_examples(train, \n",
        "#                                                                            test, \n",
        "#                                                                            'DATA_COLUMN', \n",
        "#                                                                            'LABEL_COLUMN')\n",
        "  \n",
        "# def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
        "#     features = [] # -> will hold InputFeatures to be converted later\n",
        "\n",
        "#     for e in examples:\n",
        "#         # Documentation is really strong for this method, so please take a look at it\n",
        "#         input_dict = tokenizer.encode_plus(\n",
        "#             e.text_a,\n",
        "#             add_special_tokens=True,\n",
        "#             max_length=max_length, # truncates if len(s) > max_length\n",
        "#             return_token_type_ids=True,\n",
        "#             return_attention_mask=True,\n",
        "#             pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n",
        "#             truncation=True\n",
        "#         )\n",
        "\n",
        "#         input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n",
        "#             input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
        "\n",
        "#         features.append(\n",
        "#             InputFeatures(\n",
        "#                 input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n",
        "#             )\n",
        "#         )\n",
        "\n",
        "#     def gen():\n",
        "#         for f in features:\n",
        "#             yield (\n",
        "#                 {\n",
        "#                     \"input_ids\": f.input_ids,\n",
        "#                     \"attention_mask\": f.attention_mask,\n",
        "#                     \"token_type_ids\": f.token_type_ids,\n",
        "#                 },\n",
        "#                 f.label,\n",
        "#             )\n",
        "\n",
        "#     return tf.data.Dataset.from_generator(\n",
        "#         gen,\n",
        "#         ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
        "#         (\n",
        "#             {\n",
        "#                 \"input_ids\": tf.TensorShape([None]),\n",
        "#                 \"attention_mask\": tf.TensorShape([None]),\n",
        "#                 \"token_type_ids\": tf.TensorShape([None]),\n",
        "#             },\n",
        "#             tf.TensorShape([]),\n",
        "#         ),\n",
        "#     )\n",
        "\n",
        "\n",
        "# DATA_COLUMN = 'DATA_COLUMN'\n",
        "# LABEL_COLUMN = 'LABEL_COLUMN'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haoq_CPHZQJD"
      },
      "outputs": [],
      "source": [
        "# from transformers import InputExample, InputFeatures\n",
        "# train_InputExamples, validation_InputExamples = convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN)\n",
        "# print(train_InputExamples[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2YtrAP3eb7f"
      },
      "outputs": [],
      "source": [
        "# train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
        "# train_data = train_data.shuffle(100).batch(32).repeat(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "qCkVtpYTPb2A",
        "outputId": "5db14097-ba5e-43c7-b503-279fb4aa5d96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb6cce73090>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.countplot(y_train['stars'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsOT0zY6hpaT"
      },
      "outputs": [],
      "source": [
        "# sns.countplot(y_test['stars'])\n",
        "# np.unique(y_test, counts=TRUE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKfwlIr_RQnE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgMOjo7zHdTw"
      },
      "source": [
        "**RESTARTING FROM HERE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252,
          "referenced_widgets": [
            "73434f002dbe46c79ea378970145d5ed",
            "b534f8d28b6246f49bca42b23c4cd3bb",
            "63e0c8eae8904f2bad390810777c98e8",
            "37d1df3d44d144ad90762dbb4bdd254a",
            "26b653e151f6492f8cdcbc6d61074038",
            "e176d8199eb64120b61787dd5fcbb8af",
            "d907aac6473a45edb58fe34685383ed5",
            "4251d19b14af4c7dbe6c4c84ce90463b",
            "40a671f0f7f84d3ca933eb715c4e5d8a",
            "d4789d3cf5304977975d5f956d7ca2a9",
            "ec2de9bf84804764ad790c12a68c45e7",
            "1ba8a14972b34427ad68226f0b72ea44",
            "b937ff50a6964b3484457845f619ff4a",
            "ee99bf9669ac4417b04838a72748281b",
            "ef09b288e7aa4ee28d47160ebf5cf7d0",
            "480db40009394413bf7cc77f12fde4ab",
            "b89275bc1fa94737b9fd88851bfce92d",
            "6268cf01828a44368f342d5284f27df7",
            "b5f616eded9e45c19bbe588ad8770071",
            "b82b2a422be446cc9cf0728f2423be21",
            "051b4138dcd24157a0df9266c17445ec",
            "46ccaec91e274ef48aff98b77c7a6875",
            "62276ba4f15d412395d5139f7d3c22f7",
            "83be320f115547018e302149b13cce8b",
            "a2e40e01e516407496f6c5620f938197",
            "86b50e26706e4d779f1ad0200ead4dd3",
            "84fe71e654304bb3aad6c7a4dc13d255",
            "a1b5f0116fa54d34a36abf4f71c870fa",
            "7a02648a7c0049aaa4839e894b19dd2c",
            "b33a3429d2f54ae696c8d668e3e2f5d5",
            "9a7422a24f5b4340abaa10955107f381",
            "26ac66de002c48afbb0eef6d35c1c7b3",
            "db13c917db9343419c3c360aa9677af7",
            "5db64ef8517847bf906754f03853c24a",
            "de1f7f56a66d48dfba5595c1d3e28573",
            "92a9759cee9f43b7be09b18567801928",
            "5ac92431364e4ab6bd482ec6d7dd1339",
            "d3652345846648a192c147692124e4ba",
            "55576b1e32734ddca073f9299f26a599",
            "8b185f5d36694030a3bff7a5d50b52d8",
            "2808ce6146d5477384cb62cf3523bdf3",
            "a1da462b103343a7b6de5214a26cd445",
            "94e28ff2c6874c28bc25218d72b81b92",
            "4bbc2365c1be47f9886d1b9be7c4a368"
          ]
        },
        "id": "lS63TPeGjDsB",
        "outputId": "5d0c3f02-4c0e-42c8-d728-c50e4364a982"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73434f002dbe46c79ea378970145d5ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ba8a14972b34427ad68226f0b72ea44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62276ba4f15d412395d5139f7d3c22f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5db64ef8517847bf906754f03853c24a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/502M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69rs1W_OJGQ3",
        "outputId": "93a07d04-7d2f-4308-aae7-4586bcd2e335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"RIDE RIDE RIDE!!! This is for all the bad mf'ers that love dark loud nightclubs but want to be healthy and clean up their lifestyle. Before i stepped foot into this place, I heard it was like a CULT. Lol. They are so right. I freakin love this place and I am a CULT member... even though I am anti social they accept me to be in their uplifting and fat blasting cult. No experience needed to come here... the more you go, the better you get.\\n\\nThe instructors and staff are excellent with new riders, getting them set up for how ever many times it takes you to become a pro. Everyone can ride at their own pace.\\n\\nMy tip for new riders: Ride in the back if you are self conscious. Seat hurts your bum? Try not to sit, just slow your legs but still to the beat. Breathe deeply and make sure you let your heart rate climb up to challenge yourself, and as you slow down take deep breathes. It helps you recover! \\n\\nGoal: to RIDE 100 RIDES... 29 and counting!!!!!!\",\n",
              " 'Only been here once and the vegan horchata peanut butter ice cream SLAPSSSS. So good you will wish you got an extra large and not a tiny. I think I could eat that every single day. It was delicious and I have no complaints about it other than the price. It was like $5 for 2 scoops of ice cream. Yikes. Regardless, so good! Would highly recommend.',\n",
              " 'My teen found this place. We like our coffee black, cold, and strong, and were not disappointed. We were in town for the national teachers convention #NEARA17 and staying in the North End. We were there almost daily for the entire 10 days. We need more places like TC here in CA. -Dr M',\n",
              " \"My husband and I came here for an impromptu dinner on a Saturday night around 6 pm. No reservations were needed -- we were seated right away (during baseball season I suspect this may not be the case). \\n\\nTo eat: I had three fresh oysters and the ahi tuna burger. The flavors were well balanced and a good portion size (had to take some home!). My husband had the steak medium-rare with a side of scalloped potatoes. These were also good -- but far from the best that we've had at actual steakhouses. For dessert, they have one option: toffee bread pudding. It's exactly how you'd expect it to taste: comforting, buttery, and full of rich toffee flavors. Overall, it was decently executed. It was topped with a dollop of cream (I would have loved for it to have been vanilla ice cream!). \\n\\nAll in all, the food was good. Service was good. Probably not a place I'd jump to repeat though given the price point.\",\n",
              " \"Great workout and the staff is great!  I've been going to OTF Dublin for over a year and love it.\"]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[x for x in X_train['text'][:5]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wM1Mz75EJrcI"
      },
      "outputs": [],
      "source": [
        "#import tensorflow_datasets as tfds\n",
        "\n",
        "# train_data, test_data = tfds.load(\n",
        "#     name=\"imdb_reviews\", \n",
        "#     split=('train[:80%]', 'test[80%:]'),\n",
        "#     as_supervised=True)\n",
        "\n",
        "# train_examples_batch, train_labels_batch = next(iter(train_data.batch(20000)))\n",
        "# test_examples_batch, test_labels_batch = next(iter(test_data.batch(5000)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBWowuvYKI6u"
      },
      "outputs": [],
      "source": [
        "#train_examples_batch[:5]\n",
        "#train_labels_batch[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QRVZyNwKg_E",
        "outputId": "1256b7b2-3f67-4e92-dc3b-b0671bd8f828"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=string, numpy=\n",
              "array([b\"RIDE RIDE RIDE!!! This is for all the bad mf'ers that love dark loud nightclubs but want to be healthy and clean up their lifestyle. Before i stepped foot into this place, I heard it was like a CULT. Lol. They are so right. I freakin love this place and I am a CULT member... even though I am anti social they accept me to be in their uplifting and fat blasting cult. No experience needed to come here... the more you go, the better you get.\\n\\nThe instructors and staff are excellent with new riders, getting them set up for how ever many times it takes you to become a pro. Everyone can ride at their own pace.\\n\\nMy tip for new riders: Ride in the back if you are self conscious. Seat hurts your bum? Try not to sit, just slow your legs but still to the beat. Breathe deeply and make sure you let your heart rate climb up to challenge yourself, and as you slow down take deep breathes. It helps you recover! \\n\\nGoal: to RIDE 100 RIDES... 29 and counting!!!!!!\",\n",
              "       b'Only been here once and the vegan horchata peanut butter ice cream SLAPSSSS. So good you will wish you got an extra large and not a tiny. I think I could eat that every single day. It was delicious and I have no complaints about it other than the price. It was like $5 for 2 scoops of ice cream. Yikes. Regardless, so good! Would highly recommend.',\n",
              "       b'My teen found this place. We like our coffee black, cold, and strong, and were not disappointed. We were in town for the national teachers convention #NEARA17 and staying in the North End. We were there almost daily for the entire 10 days. We need more places like TC here in CA. -Dr M',\n",
              "       b\"My husband and I came here for an impromptu dinner on a Saturday night around 6 pm. No reservations were needed -- we were seated right away (during baseball season I suspect this may not be the case). \\n\\nTo eat: I had three fresh oysters and the ahi tuna burger. The flavors were well balanced and a good portion size (had to take some home!). My husband had the steak medium-rare with a side of scalloped potatoes. These were also good -- but far from the best that we've had at actual steakhouses. For dessert, they have one option: toffee bread pudding. It's exactly how you'd expect it to taste: comforting, buttery, and full of rich toffee flavors. Overall, it was decently executed. It was topped with a dollop of cream (I would have loved for it to have been vanilla ice cream!). \\n\\nAll in all, the food was good. Service was good. Probably not a place I'd jump to repeat though given the price point.\",\n",
              "       b\"Great workout and the staff is great!  I've been going to OTF Dublin for over a year and love it.\"],\n",
              "      dtype=object)>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.convert_to_tensor(X_train['text'][:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmYxTPvYIHx2"
      },
      "outputs": [],
      "source": [
        "num_train_examples = 80000\n",
        "num_test_examples = 20000\n",
        "\n",
        "max_length = 512\n",
        "\n",
        "X_train_tokenized = tokenizer([str(x.numpy())[2:] for x in tf.convert_to_tensor(X_train['text'][:num_train_examples])], \n",
        "              max_length=max_length,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')\n",
        "\n",
        "y_train_tokenized = tf.convert_to_tensor(y_train['stars'][:num_train_examples])\n",
        "\n",
        "x_test_tokenized = tokenizer([str(x.numpy())[2:] for x in tf.convert_to_tensor(X_test['text'][:num_test_examples])], \n",
        "              max_length=max_length,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')\n",
        "\n",
        "y_test_tokenized = tf.convert_to_tensor(y_test['stars'][:num_test_examples])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuCmfPlLLKrk",
        "outputId": "b3a0a3c6-e108-440c-d897-1e5c6ee0a6d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(80000, 512), dtype=int32, numpy=\n",
              "array([[  101,   155,  9949, ...,     0,     0,     0],\n",
              "       [  101,  2809,  1151, ...,     0,     0,     0],\n",
              "       [  101,  1422, 13964, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101,  2038,  1282, ...,     0,     0,     0],\n",
              "       [  101,  1258,  3776, ...,     0,     0,     0],\n",
              "       [  101,  2185,  1139, ...,     0,     0,     0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(80000, 512), dtype=int32, numpy=\n",
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(80000, 512), dtype=int32, numpy=\n",
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WT3Dzc0896x",
        "outputId": "1cd9d450-7e73-4a98-81fd-ea5a55791276"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(80000,), dtype=float64, numpy=array([4., 4., 4., ..., 3., 3., 4.])>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4eAZ9jNYl7z"
      },
      "outputs": [],
      "source": [
        "# ?bert_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaUJpDvQLiHD"
      },
      "outputs": [],
      "source": [
        "#bert_out = bert_model(X_train_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uinXzHkGNHvk"
      },
      "outputs": [],
      "source": [
        "#bert_out[0].numpy().shape\n",
        "# Batch size, max length, encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZivzjOcNmni"
      },
      "outputs": [],
      "source": [
        "#bert_out[1].numpy().shape\n",
        "# this is the classification encoding, which we will feed to the classification layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPQwsmjWNyFJ"
      },
      "outputs": [],
      "source": [
        "input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='input_ids_layer')\n",
        "token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='token_types_ids_layer')\n",
        "attention_masks = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='attention_masks_layer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXRii7xYOiNQ"
      },
      "outputs": [],
      "source": [
        "bert_inputs = {'input_ids': input_ids,\n",
        "               'token_type_ids': token_type_ids,\n",
        "               'attention_masks': attention_masks\n",
        "               }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdMmOhyPPDs6"
      },
      "outputs": [],
      "source": [
        "bert_out = bert_model(bert_inputs)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTEdzGeWQctH"
      },
      "outputs": [],
      "source": [
        "hidden_out = tf.keras.layers.Dense(200, activation='relu')(bert_out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R-ot6LaQc5u"
      },
      "outputs": [],
      "source": [
        "classification_out = tf.keras.layers.Dense(5, activation='sigmoid')(hidden_out)\n",
        "# Used 6 categories just to see if this would run (knowing there isn't a 6th category)...\n",
        "# Need to either 1-hot encode the data here (and use categorical cross-entropy) or transform the prediction categories to 0-4 (sparse doesn't like starting at 1 instead of 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gz5YWt9P9CA"
      },
      "outputs": [],
      "source": [
        "classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_masks], outputs=[classification_out])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icZM-pI0u0ai"
      },
      "outputs": [],
      "source": [
        "# ?tf.keras.losses.SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWGYdNkZROZW"
      },
      "outputs": [],
      "source": [
        "classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=.00001), \n",
        "                             loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                             metrics='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hApspdAXQO5I",
        "outputId": "01fa2d03-68b0-4a7b-f634-9641312f2f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " attention_masks_layer (InputLa  [(None, 512)]       0           []                               \n",
            " yer)                                                                                             \n",
            "                                                                                                  \n",
            " input_ids_layer (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " token_types_ids_layer (InputLa  [(None, 512)]       0           []                               \n",
            " yer)                                                                                             \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['attention_masks_layer[0][0]',  \n",
            "                                thPoolingAndCrossAt               'input_ids_layer[0][0]',        \n",
            "                                tentions(last_hidde               'token_types_ids_layer[0][0]']  \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 200)          153800      ['tf_bert_model[0][1]']          \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 5)            1005        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,465,077\n",
            "Trainable params: 108,465,077\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "classification_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH-b3-t9sy6c",
        "outputId": "5224fb11-ac9b-4504-e534-66c9d8ed5a56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "8000/8000 [==============================] - 5998s 749ms/step - loss: 0.7501 - accuracy: 0.6829 - val_loss: 0.6542 - val_accuracy: 0.7204\n",
            "Epoch 2/3\n",
            "8000/8000 [==============================] - 5986s 748ms/step - loss: 0.6036 - accuracy: 0.7426 - val_loss: 0.6369 - val_accuracy: 0.7265\n",
            "Epoch 3/3\n",
            "8000/8000 [==============================] - 5987s 748ms/step - loss: 0.4996 - accuracy: 0.7905 - val_loss: 0.6637 - val_accuracy: 0.7285\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb5e6399c90>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classification_model.fit([X_train_tokenized.input_ids, X_train_tokenized.token_type_ids, X_train_tokenized.attention_mask],\n",
        "                         y_train_tokenized,\n",
        "                         validation_data=([x_test_tokenized.input_ids, x_test_tokenized.token_type_ids, x_test_tokenized.attention_mask],\n",
        "                                          y_test_tokenized),\n",
        "                         epochs=3,\n",
        "                         batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8ahRO-38e7k"
      },
      "outputs": [],
      "source": [
        "#tokenize the 80k for stage 2, then feed into preds\n",
        "num_train_examples = 80000\n",
        "\n",
        "max_length = 512\n",
        "\n",
        "X_train_stage_2_tokenized = tokenizer([str(x.numpy())[2:] for x in tf.convert_to_tensor(X_train_stage_2['text'][:num_train_examples])], \n",
        "              max_length=max_length,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m6EtlVB-UYr",
        "outputId": "7f679580-40b3-409d-8eec-4a23003190fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(80000, 512), dtype=int32, numpy=\n",
              "array([[  101,  1188,  1282, ...,     0,     0,     0],\n",
              "       [  101,  3982,   170, ...,     0,     0,     0],\n",
              "       [  101,   146,  1567, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101,   146,  3055, ...,     0,     0,     0],\n",
              "       [  101, 22515,  9552, ...,     0,     0,     0],\n",
              "       [  101,  1188,  1282, ...,     0,     0,     0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(80000, 512), dtype=int32, numpy=\n",
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(80000, 512), dtype=int32, numpy=\n",
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_stage_2_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a9dAQbIv05k8"
      },
      "outputs": [],
      "source": [
        "predictions = classification_model.predict([X_train_stage_2_tokenized.input_ids, \n",
        "                                            X_train_stage_2_tokenized.token_type_ids, \n",
        "                                            X_train_stage_2_tokenized.attention_mask]#,\n",
        "                             #batch_size=1,\n",
        "                             #steps=80000)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BR6As7bi4_hP",
        "outputId": "784020fc-e628-4183-d9c5-1c90e5001564"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(80000, 5)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SBN4_kD15xnx",
        "outputId": "262be0a9-e259-4a81-f155-1efbe2f83d24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.02485654, 0.00541492, 0.05600293, 0.7715309 , 0.9965989 ],\n",
              "       [0.00448075, 0.01005913, 0.39194813, 0.94505227, 0.9398036 ],\n",
              "       [0.00493906, 0.00781136, 0.32871127, 0.9510869 , 0.9584817 ],\n",
              "       ...,\n",
              "       [0.0096079 , 0.00909165, 0.1656906 , 0.88125306, 0.98347497],\n",
              "       [0.00348651, 0.0122392 , 0.46762046, 0.95101213, 0.8846211 ],\n",
              "       [0.00848686, 0.05305507, 0.70383906, 0.9188478 , 0.7348218 ]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df = pd.DataFrame(predictions)\n",
        "predictions_df.to_csv('BERT_Predictions_80k_stage_2.csv')"
      ],
      "metadata": {
        "id": "Gme4kzoxKmMI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "PIVaJKIwkx8s"
      },
      "outputs": [],
      "source": [
        "preds = []\n",
        "for pred in predictions:\n",
        "  preds.append(np.argmax(pred)+1)\n",
        "\n",
        "np.unique(preds)\n",
        "\n",
        "predictions_df_1_to_5 = pd.DataFrame(preds)\n",
        "predictions_df_1_to_5.to_csv('BERT_Predictions_80k_stage_2_1_to_5.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWjtQIl-a4Nj",
        "outputId": "a921a7f7-caf2-48a1-93ed-0a09a1432abf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7231625"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# check the accuracy of stage 2 preds\n",
        "np.sum(predictions_df_1_to_5[0] == y_train_stage_2['stars'])/80000\n",
        "# Based on this, the BERT model spit out accurate predictions for 72.3% of the 80k stage 2 examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdCa2pH82Hmj"
      },
      "source": [
        "**Problems to Address**\n",
        "* Need to tap into local resources (GPU) to speed processing - may need to specify in the model to utilize the GPU (and change runtime settings)\n",
        "* ***RESOLVED*** Accuracy could be quite low because of such a small data set\n",
        "* ***INCORPORATED*** We should get another dataset that is class-balanced\n",
        "* ***FIXED:*** Loss is way too low... need to investigate this, because it should start higher... first thought was learning rate was too high, but stayed the same at .01 Adam. Maybe this has more to do with the # of categories, which would exmplain the low accuracy and the low loss\n",
        "* ***DONE:*** Need to resolve the wrong number of categories predicted (should be 5, only returning 1)... I think I have the wrong number of neurons in the final prediction layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrF5M9oS9yjM"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "DustinBERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "051b4138dcd24157a0df9266c17445ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ba8a14972b34427ad68226f0b72ea44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b937ff50a6964b3484457845f619ff4a",
              "IPY_MODEL_ee99bf9669ac4417b04838a72748281b",
              "IPY_MODEL_ef09b288e7aa4ee28d47160ebf5cf7d0"
            ],
            "layout": "IPY_MODEL_480db40009394413bf7cc77f12fde4ab"
          }
        },
        "26ac66de002c48afbb0eef6d35c1c7b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26b653e151f6492f8cdcbc6d61074038": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2808ce6146d5477384cb62cf3523bdf3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37d1df3d44d144ad90762dbb4bdd254a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4789d3cf5304977975d5f956d7ca2a9",
            "placeholder": "​",
            "style": "IPY_MODEL_ec2de9bf84804764ad790c12a68c45e7",
            "value": " 208k/208k [00:00&lt;00:00, 623kB/s]"
          }
        },
        "40a671f0f7f84d3ca933eb715c4e5d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4251d19b14af4c7dbe6c4c84ce90463b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46ccaec91e274ef48aff98b77c7a6875": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "480db40009394413bf7cc77f12fde4ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bbc2365c1be47f9886d1b9be7c4a368": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55576b1e32734ddca073f9299f26a599": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ac92431364e4ab6bd482ec6d7dd1339": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94e28ff2c6874c28bc25218d72b81b92",
            "placeholder": "​",
            "style": "IPY_MODEL_4bbc2365c1be47f9886d1b9be7c4a368",
            "value": " 502M/502M [00:08&lt;00:00, 65.0MB/s]"
          }
        },
        "5db64ef8517847bf906754f03853c24a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de1f7f56a66d48dfba5595c1d3e28573",
              "IPY_MODEL_92a9759cee9f43b7be09b18567801928",
              "IPY_MODEL_5ac92431364e4ab6bd482ec6d7dd1339"
            ],
            "layout": "IPY_MODEL_d3652345846648a192c147692124e4ba"
          }
        },
        "62276ba4f15d412395d5139f7d3c22f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83be320f115547018e302149b13cce8b",
              "IPY_MODEL_a2e40e01e516407496f6c5620f938197",
              "IPY_MODEL_86b50e26706e4d779f1ad0200ead4dd3"
            ],
            "layout": "IPY_MODEL_84fe71e654304bb3aad6c7a4dc13d255"
          }
        },
        "6268cf01828a44368f342d5284f27df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63e0c8eae8904f2bad390810777c98e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4251d19b14af4c7dbe6c4c84ce90463b",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40a671f0f7f84d3ca933eb715c4e5d8a",
            "value": 213450
          }
        },
        "73434f002dbe46c79ea378970145d5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b534f8d28b6246f49bca42b23c4cd3bb",
              "IPY_MODEL_63e0c8eae8904f2bad390810777c98e8",
              "IPY_MODEL_37d1df3d44d144ad90762dbb4bdd254a"
            ],
            "layout": "IPY_MODEL_26b653e151f6492f8cdcbc6d61074038"
          }
        },
        "7a02648a7c0049aaa4839e894b19dd2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83be320f115547018e302149b13cce8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1b5f0116fa54d34a36abf4f71c870fa",
            "placeholder": "​",
            "style": "IPY_MODEL_7a02648a7c0049aaa4839e894b19dd2c",
            "value": "Downloading: 100%"
          }
        },
        "84fe71e654304bb3aad6c7a4dc13d255": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86b50e26706e4d779f1ad0200ead4dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26ac66de002c48afbb0eef6d35c1c7b3",
            "placeholder": "​",
            "style": "IPY_MODEL_db13c917db9343419c3c360aa9677af7",
            "value": " 570/570 [00:00&lt;00:00, 16.5kB/s]"
          }
        },
        "8b185f5d36694030a3bff7a5d50b52d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92a9759cee9f43b7be09b18567801928": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2808ce6146d5477384cb62cf3523bdf3",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1da462b103343a7b6de5214a26cd445",
            "value": 526681800
          }
        },
        "94e28ff2c6874c28bc25218d72b81b92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a7422a24f5b4340abaa10955107f381": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1b5f0116fa54d34a36abf4f71c870fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1da462b103343a7b6de5214a26cd445": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2e40e01e516407496f6c5620f938197": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b33a3429d2f54ae696c8d668e3e2f5d5",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a7422a24f5b4340abaa10955107f381",
            "value": 570
          }
        },
        "b33a3429d2f54ae696c8d668e3e2f5d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b534f8d28b6246f49bca42b23c4cd3bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e176d8199eb64120b61787dd5fcbb8af",
            "placeholder": "​",
            "style": "IPY_MODEL_d907aac6473a45edb58fe34685383ed5",
            "value": "Downloading: 100%"
          }
        },
        "b5f616eded9e45c19bbe588ad8770071": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b82b2a422be446cc9cf0728f2423be21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b89275bc1fa94737b9fd88851bfce92d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b937ff50a6964b3484457845f619ff4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b89275bc1fa94737b9fd88851bfce92d",
            "placeholder": "​",
            "style": "IPY_MODEL_6268cf01828a44368f342d5284f27df7",
            "value": "Downloading: 100%"
          }
        },
        "d3652345846648a192c147692124e4ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4789d3cf5304977975d5f956d7ca2a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d907aac6473a45edb58fe34685383ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db13c917db9343419c3c360aa9677af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de1f7f56a66d48dfba5595c1d3e28573": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55576b1e32734ddca073f9299f26a599",
            "placeholder": "​",
            "style": "IPY_MODEL_8b185f5d36694030a3bff7a5d50b52d8",
            "value": "Downloading: 100%"
          }
        },
        "e176d8199eb64120b61787dd5fcbb8af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec2de9bf84804764ad790c12a68c45e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee99bf9669ac4417b04838a72748281b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5f616eded9e45c19bbe588ad8770071",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b82b2a422be446cc9cf0728f2423be21",
            "value": 29
          }
        },
        "ef09b288e7aa4ee28d47160ebf5cf7d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_051b4138dcd24157a0df9266c17445ec",
            "placeholder": "​",
            "style": "IPY_MODEL_46ccaec91e274ef48aff98b77c7a6875",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.25kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}