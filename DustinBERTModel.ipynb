{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DustinBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# # Need to tap local runtime resources\n",
        "# !pip install jupyterlab\n",
        "# !pip install jupyter_http_over_ws\n",
        "# !jupyter serverextension enable --py jupyter_http_over_ws"
      ],
      "metadata": {
        "id": "45surhmEZ2-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YjmX9yWSRu-",
        "outputId": "64c2c991-009d-487f-a6f6-658507cb9661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "fatal: destination path 'W266_Group_Project' already exists and is not an empty directory.\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.2.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.2)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "# Setup for Google Colab\n",
        "#!pip install tensorflow-gpu\n",
        "!pip install transformers\n",
        "!git clone https://github.com/CodyBurker/W266_Group_Project\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h8jdCX2UCGF",
        "outputId": "0855f685-03a3-409d-ac38-81fa5646103f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar 21 23:22:22 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, TFBertModel, TFBertForSequenceClassification\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "l52ZY3KWjMPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def read_in_data(path=\"W266_Group_Project/\"):\n",
        "#     import pandas as pd\n",
        "#     X_train = pd.read_csv(path + \"x_train_sampled_yelp_data.csv\")\n",
        "#     y_train = pd.read_csv(path + \"y_train_sampled_yelp_data.csv\")\n",
        "#     X_test = pd.read_csv(path + \"x_test_sampled_yelp_data.csv\")\n",
        "#     y_test = pd.read_csv(path + \"y_test_sampled_yelp_data.csv\")\n",
        "#     return X_train, X_test, y_train, y_test\n",
        "# X_train, X_test, y_train, y_test = read_in_data()"
      ],
      "metadata": {
        "id": "8BV98hg0SexQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_in_data(path=\"W266_Group_Project/\"):\n",
        "    import pandas as pd\n",
        "    X_train = pd.read_csv(path + \"x_train_balanced.csv\")\n",
        "    y_train = pd.read_csv(path + \"y_train_balanced.csv\")\n",
        "    X_test = pd.read_csv(path + \"x_test_balanced.csv\")\n",
        "    y_test = pd.read_csv(path + \"y_test_balanced.csv\")\n",
        "    return X_train, X_test, y_train, y_test\n",
        "X_train, X_test, y_train, y_test = read_in_data()"
      ],
      "metadata": {
        "id": "LllM6Jmj5n5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['text'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "NSwJgj02VAWn",
        "outputId": "443e17d6-7117-49a0-b342-04c5b9ef5986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Will definitely be using Cooper Party Rentals again! Not only do they have more than fair pricing, the owner was super nice and quick to respond to any of my questions or concerns. We rented 4 round tables and 30 white chairs. Everything was dropped off and picked up super conveniently and in a timely manner.  We had initially planned to have our event in May for my sister's grad party and had to reschedule due to COVID. Dane was super understanding and flexible around our new proposed dates.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train['stars'] = y_train['stars'] - 1\n",
        "y_test['stars'] = y_test['stars'] - 1\n",
        "# shifting predicted categories down by 1 to work in the sparse_cateforial_entropy loss below "
      ],
      "metadata": {
        "id": "gKMPbHMNVSv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train['stars']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xHzbjruXTWR",
        "outputId": "03fed30a-af8b-46dd-cd02-18e2acb3b502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        3.0\n",
              "1        4.0\n",
              "2        0.0\n",
              "3        3.0\n",
              "4        4.0\n",
              "        ... \n",
              "79995    0.0\n",
              "79996    2.0\n",
              "79997    0.0\n",
              "79998    2.0\n",
              "79999    0.0\n",
              "Name: stars, Length: 80000, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring options from https://towardsdatascience.com/sentiment-analysis-in-10-minutes-with-bert-and-hugging-face-294e8a04b671\n",
        "# from transformers import TFBertForSequenceClassification\n",
        "# ?TFBertForSequenceClassification"
      ],
      "metadata": {
        "id": "YrGTZJDoINB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "#import tensorflow as tf\n",
        "\n",
        "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "#model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "#inputs = tokenizer(\"Hello, my dog is ugly, mean, and bad\", return_tensors=\"tf\")\n",
        "#inputs[\"labels\"] = tf.reshape(tf.constant(1), (-1, 1))  # Batch size 1\n",
        "\n",
        "#outputs = model(inputs)\n",
        "#loss = outputs.loss\n",
        "#logits = outputs.logits"
      ],
      "metadata": {
        "id": "pVcrNh9ji8D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the layers in the BERT base model\n",
        "#[i.name for i in model.weights]"
      ],
      "metadata": {
        "id": "SDdYKFe-E0p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def how_many_tokens(input_examples, tokenizer=tokenizer,\n",
        "#                     quantiles = [0, .25, .5, .75, 1]):\n",
        "#   \"\"\" \n",
        "#   Determine the desired quantiles calculated from the length (in token IDs) of \n",
        "#   provided text examples using a desired tokenizer.\n",
        "  \n",
        "#   Input: list of examples\n",
        "\n",
        "#   Output: Number of token IDs at quantiles in any of the given input examples \n",
        "#   (excluding special token IDs such as CLS, UNK, SEP) \n",
        "#   \"\"\" \n",
        "\n",
        "#   input_token_id_lengths = []\n",
        "#   for i in input_examples:\n",
        "#     tokens = tokenizer.tokenize(i)\n",
        "#     token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "#     input_token_id_lengths.append(len(token_ids))\n",
        "\n",
        "#   return np.quantile(input_token_id_lengths, quantiles), input_token_id_lengths\n",
        "\n",
        "# # The results of running this function on the training text examples (100K) was\n",
        "# # 4,406 max token IDs - pretty long - and the below quantiles:\n",
        "# # array([1.000e+00, 5.600e+01, 1.010e+02, 1.780e+02, 4.406e+03])\n",
        "# # how_many_tokens(X_train['text'])\n",
        "\n",
        "# # The results for below, same run on test examples yielded: \n",
        "# # array([   2.,   56.,  100.,  178., 1385.])\n",
        "# # how_many_tokens(X_test['text'])"
      ],
      "metadata": {
        "id": "4wKZxl0LPLNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# While the max length is 4,406, only 2.2% of examples would be truncated if\n",
        "# we set the max length at 512 (for padding purposes), as seen below\n",
        "# quantiles, token_lengths = how_many_tokens(X_train['text'])\n",
        "# print(quantiles)\n",
        "# print('Proportion of examples > 512 tokens:', (np.sum(np.array(token_lengths)>512)/(len(token_lengths))))\n",
        "\n",
        "# Setting max length based on above\n",
        "# max_length = 512"
      ],
      "metadata": {
        "id": "YvKlstgnrNMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def examples_to_BERT_inputs(input_examples, input_labels, tokenizer=tokenizer, \n",
        "#                             max_length=max_length):\n",
        "#   #c= 0\n",
        "#   input_ids = []\n",
        "#   attention_mask = []\n",
        "#   #labels = []\n",
        "\n",
        "#   for i in input_examples:\n",
        "#     encoding = tokenizer.encode_plus(\n",
        "#         i,\n",
        "#         truncation = True, \n",
        "#         add_special_tokens = True,\n",
        "#         padding = 'max_length',\n",
        "#         return_attention_mask = True#,\n",
        "#         #return_tensors='tf'\n",
        "#     )\n",
        "\n",
        "#     input_ids.append(encoding['input_ids'])\n",
        "#     attention_mask.append(encoding['attention_mask'])\n",
        "#     #labels.append(input_labels[c])\n",
        "\n",
        "#     #c+=1\n",
        "\n",
        "#   return {'input_ids': input_ids, 'attention_mask': attention_mask}"
      ],
      "metadata": {
        "id": "_S_Q4u_4j9uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to see if the base model is performing as expected\n",
        "# results_base = model(examples_to_BERT_inputs(X_train['text'][:100], y_train['stars'][:100]))"
      ],
      "metadata": {
        "id": "cjbVDGf6Gj0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# results_base"
      ],
      "metadata": {
        "id": "H9SppiJWG6KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Look at the shape of every layer in the pretrained model\n",
        "#for layer in range(len(bert.layers[0].weights))[:10]:\n",
        "    #print(layer)\n",
        "    #print('Layer name: \\t', bert.layers[0].weights[layer].name)\n",
        "    #print('Layer shape: \\t', bert.layers[0].weights[layer].shape)"
      ],
      "metadata": {
        "id": "Mf2vDeMDwT3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer.tokenize('Testing to see how this BERT tokenizer splits various kinds of words, sometimes unusually')"
      ],
      "metadata": {
        "id": "iKNL610WoCrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer.convert_tokens_to_ids([\n",
        "#                                  '[CLS]', \n",
        "#                                  'Testing',\n",
        "#                                  'to',\n",
        "#                                  'see',\n",
        "#                                  'how',\n",
        "#                                  'this', \n",
        "#                                  'works', \n",
        "#                                  '[SEP]'])"
      ],
      "metadata": {
        "id": "ZayxKUGEpiSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer.convert_ids_to_tokens([101])"
      ],
      "metadata": {
        "id": "c4LYUokIpsFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Establish bare base pretrained BERT model, and see layers\n",
        "# bert = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "# note the model name / path is a string - the *model id* of a pretrained model \n",
        "# hosted inside a model repo on huggingface.co"
      ],
      "metadata": {
        "id": "YLJ9gvujrESq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#curious to see example weights at the first layer\n",
        "# bert.layers[0].weights[0]"
      ],
      "metadata": {
        "id": "MGVv42Oyrk26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resource used to guide work: \n",
        "# https://raviteja-ganta.github.io/sentiment-analysis-using-bert-and-hugging-face"
      ],
      "metadata": {
        "id": "Z1jtEBclMpHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# outputs[0]"
      ],
      "metadata": {
        "id": "ouuCWx0tjJxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train['DATA_COLUMN'] = pd.DataFrame(X_train['text'])\n",
        "# train['LABEL_COLUMN'] = y_train['stars']\n",
        "# test['DATA_COLUMN'] = pd.DataFrame(X_test['text'])\n",
        "# test['LABEL_COLUMN'] = y_test['stars']\n",
        "\n",
        "# #pd.DataFrame(test[['text', 'stars']])\n",
        "# test"
      ],
      "metadata": {
        "id": "fqKozcegaAYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN): \n",
        "#   train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
        "#                                                           text_a = x[DATA_COLUMN], \n",
        "#                                                           text_b = None,\n",
        "#                                                           label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "#   validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
        "#                                                           text_a = x[DATA_COLUMN], \n",
        "#                                                           text_b = None,\n",
        "#                                                           label = x[LABEL_COLUMN]), axis = 1)\n",
        "  \n",
        "#   return train_InputExamples, validation_InputExamples\n",
        "\n",
        "#   train_InputExamples, validation_InputExamples = convert_data_to_examples(train, \n",
        "#                                                                            test, \n",
        "#                                                                            'DATA_COLUMN', \n",
        "#                                                                            'LABEL_COLUMN')\n",
        "  \n",
        "# def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
        "#     features = [] # -> will hold InputFeatures to be converted later\n",
        "\n",
        "#     for e in examples:\n",
        "#         # Documentation is really strong for this method, so please take a look at it\n",
        "#         input_dict = tokenizer.encode_plus(\n",
        "#             e.text_a,\n",
        "#             add_special_tokens=True,\n",
        "#             max_length=max_length, # truncates if len(s) > max_length\n",
        "#             return_token_type_ids=True,\n",
        "#             return_attention_mask=True,\n",
        "#             pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n",
        "#             truncation=True\n",
        "#         )\n",
        "\n",
        "#         input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n",
        "#             input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
        "\n",
        "#         features.append(\n",
        "#             InputFeatures(\n",
        "#                 input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n",
        "#             )\n",
        "#         )\n",
        "\n",
        "#     def gen():\n",
        "#         for f in features:\n",
        "#             yield (\n",
        "#                 {\n",
        "#                     \"input_ids\": f.input_ids,\n",
        "#                     \"attention_mask\": f.attention_mask,\n",
        "#                     \"token_type_ids\": f.token_type_ids,\n",
        "#                 },\n",
        "#                 f.label,\n",
        "#             )\n",
        "\n",
        "#     return tf.data.Dataset.from_generator(\n",
        "#         gen,\n",
        "#         ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
        "#         (\n",
        "#             {\n",
        "#                 \"input_ids\": tf.TensorShape([None]),\n",
        "#                 \"attention_mask\": tf.TensorShape([None]),\n",
        "#                 \"token_type_ids\": tf.TensorShape([None]),\n",
        "#             },\n",
        "#             tf.TensorShape([]),\n",
        "#         ),\n",
        "#     )\n",
        "\n",
        "\n",
        "# DATA_COLUMN = 'DATA_COLUMN'\n",
        "# LABEL_COLUMN = 'LABEL_COLUMN'"
      ],
      "metadata": {
        "id": "vocYmMv1UNv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import InputExample, InputFeatures\n",
        "# train_InputExamples, validation_InputExamples = convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN)\n",
        "# print(train_InputExamples[0])"
      ],
      "metadata": {
        "id": "haoq_CPHZQJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
        "# train_data = train_data.shuffle(100).batch(32).repeat(2)"
      ],
      "metadata": {
        "id": "Q2YtrAP3eb7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(y_train['stars'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "qCkVtpYTPb2A",
        "outputId": "0a892e8f-e772-447a-9352-93d8d29cf1db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb429fd9350>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sns.countplot(y_test['stars'])\n",
        "# np.unique(y_test, counts=TRUE)"
      ],
      "metadata": {
        "id": "XsOT0zY6hpaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CKfwlIr_RQnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RESTARTING FROM HERE**"
      ],
      "metadata": {
        "id": "TgMOjo7zHdTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS63TPeGjDsB",
        "outputId": "e6b44032-6236-4d8d-ede1-a4ef3cfef3bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[x for x in X_train['text'][:5]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69rs1W_OJGQ3",
        "outputId": "077aeec7-2623-4610-f592-4510c8df56da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This place gives so much food.. I felt like I wasted.. everything was great.. service she was sweet',\n",
              " \"Will definitely be using Cooper Party Rentals again! Not only do they have more than fair pricing, the owner was super nice and quick to respond to any of my questions or concerns. We rented 4 round tables and 30 white chairs. Everything was dropped off and picked up super conveniently and in a timely manner.  We had initially planned to have our event in May for my sister's grad party and had to reschedule due to COVID. Dane was super understanding and flexible around our new proposed dates.\",\n",
              " \"I watched the woman making my coffee use a dirty rag that she just wiped the counters with on my lid. I asked for a new lid and she gave me an attitude. That's dangerously unsanitary. Train your employees.\",\n",
              " 'Good value, tasty food, quick service. A nice alternative when I get tired of chipotle',\n",
              " \"I love Yats! I thought I wrote a review for Yats before but maybe I haven't and that's hella shocking because Yats is life! \\n\\nYats is creole comfort food that some may beg to differ depending on their taste buds but I love Yats. I will be in NOLA in July and I will compare but I am sure my buds will say Yats lol \\n\\nWhatever your vice is, Yats is the way to go. They used to give out IOU's for those that did not have cash and only cards which screamed loved for me. They now have CC machines so too bad those who were wishing on a possible eat here, play later idea. \\n\\nYats has meals for both vegetarians and meatatarians. Their BB is the boss! It's black beans and corn, sweet and spicy. They also have many other vegetarian options. Their crawfish etouffee is life as well. Anything really is great here. Get extra bread to sop up the back tray pockets. \\n\\nAffordable, flavorful, you won't be disappointed!\"]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import tensorflow_datasets as tfds\n",
        "\n",
        "# train_data, test_data = tfds.load(\n",
        "#     name=\"imdb_reviews\", \n",
        "#     split=('train[:80%]', 'test[80%:]'),\n",
        "#     as_supervised=True)\n",
        "\n",
        "# train_examples_batch, train_labels_batch = next(iter(train_data.batch(20000)))\n",
        "# test_examples_batch, test_labels_batch = next(iter(test_data.batch(5000)))"
      ],
      "metadata": {
        "id": "wM1Mz75EJrcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_examples_batch[:5]\n",
        "#train_labels_batch[:5]"
      ],
      "metadata": {
        "id": "zBWowuvYKI6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.convert_to_tensor(X_train['text'][:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QRVZyNwKg_E",
        "outputId": "0bada492-1ea2-4a75-8527-eac548800032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=string, numpy=\n",
              "array([b'This place gives so much food.. I felt like I wasted.. everything was great.. service she was sweet',\n",
              "       b\"Will definitely be using Cooper Party Rentals again! Not only do they have more than fair pricing, the owner was super nice and quick to respond to any of my questions or concerns. We rented 4 round tables and 30 white chairs. Everything was dropped off and picked up super conveniently and in a timely manner.  We had initially planned to have our event in May for my sister's grad party and had to reschedule due to COVID. Dane was super understanding and flexible around our new proposed dates.\",\n",
              "       b\"I watched the woman making my coffee use a dirty rag that she just wiped the counters with on my lid. I asked for a new lid and she gave me an attitude. That's dangerously unsanitary. Train your employees.\",\n",
              "       b'Good value, tasty food, quick service. A nice alternative when I get tired of chipotle',\n",
              "       b\"I love Yats! I thought I wrote a review for Yats before but maybe I haven't and that's hella shocking because Yats is life! \\n\\nYats is creole comfort food that some may beg to differ depending on their taste buds but I love Yats. I will be in NOLA in July and I will compare but I am sure my buds will say Yats lol \\n\\nWhatever your vice is, Yats is the way to go. They used to give out IOU's for those that did not have cash and only cards which screamed loved for me. They now have CC machines so too bad those who were wishing on a possible eat here, play later idea. \\n\\nYats has meals for both vegetarians and meatatarians. Their BB is the boss! It's black beans and corn, sweet and spicy. They also have many other vegetarian options. Their crawfish etouffee is life as well. Anything really is great here. Get extra bread to sop up the back tray pockets. \\n\\nAffordable, flavorful, you won't be disappointed!\"],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_examples = 80000\n",
        "num_test_examples = 20000\n",
        "\n",
        "max_length = 512\n",
        "\n",
        "X_train_tokenized = tokenizer([str(x.numpy())[2:] for x in tf.convert_to_tensor(X_train['text'][:num_train_examples])], \n",
        "              max_length=max_length,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')\n",
        "\n",
        "y_train_tokenized = tf.convert_to_tensor(y_train['stars'][:num_train_examples])\n",
        "\n",
        "x_test_tokenized = tokenizer([str(x.numpy())[2:] for x in tf.convert_to_tensor(X_test['text'][:num_test_examples])], \n",
        "              max_length=max_length,\n",
        "              truncation=True,\n",
        "              padding='max_length', \n",
        "              return_tensors='tf')\n",
        "\n",
        "y_test_tokenized = tf.convert_to_tensor(y_test['stars'][:num_test_examples])"
      ],
      "metadata": {
        "id": "lmYxTPvYIHx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuCmfPlLLKrk",
        "outputId": "68fbcf1b-19ca-4113-9efc-7fc3be47b805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(80000, 512), dtype=int32, numpy=\n",
              "array([[  101,  1188,  1282, ...,     0,     0,     0],\n",
              "       [  101,  3100,  5397, ...,     0,     0,     0],\n",
              "       [  101,   146,  2542, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101,  5033,  1110, ...,     0,     0,     0],\n",
              "       [  101, 23158,  1204, ...,     0,     0,     0],\n",
              "       [  101,  9800, 27788, ...,     0,     0,     0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(80000, 512), dtype=int32, numpy=\n",
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(80000, 512), dtype=int32, numpy=\n",
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ?bert_model()"
      ],
      "metadata": {
        "id": "k4eAZ9jNYl7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bert_out = bert_model(X_train_tokenized)"
      ],
      "metadata": {
        "id": "HaUJpDvQLiHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bert_out[0].numpy().shape\n",
        "# Batch size, max length, encoding"
      ],
      "metadata": {
        "id": "uinXzHkGNHvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bert_out[1].numpy().shape\n",
        "# this is the classification encoding, which we will feed to the classification layer"
      ],
      "metadata": {
        "id": "wZivzjOcNmni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='input_ids_layer')\n",
        "token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='token_types_ids_layer')\n",
        "attention_masks = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='attention_masks_layer')"
      ],
      "metadata": {
        "id": "OPQwsmjWNyFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_inputs = {'input_ids': input_ids,\n",
        "               'token_type_ids': token_type_ids,\n",
        "               'attention_masks': attention_masks\n",
        "               }"
      ],
      "metadata": {
        "id": "IXRii7xYOiNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_out = bert_model(bert_inputs)[1]"
      ],
      "metadata": {
        "id": "PdMmOhyPPDs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_out = tf.keras.layers.Dense(200, activation='relu')(bert_out)\n"
      ],
      "metadata": {
        "id": "iTEdzGeWQctH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_out = tf.keras.layers.Dense(5, activation='sigmoid')(hidden_out)\n",
        "# Used 6 categories just to see if this would run (knowing there isn't a 6th category)...\n",
        "# Need to either 1-hot encode the data here (and use categorical cross-entropy) or transform the prediction categories to 0-4 (sparse doesn't like starting at 1 instead of 0)"
      ],
      "metadata": {
        "id": "0R-ot6LaQc5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_masks], outputs=[classification_out])"
      ],
      "metadata": {
        "id": "7gz5YWt9P9CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ?tf.keras.losses.SparseCategoricalCrossentropy"
      ],
      "metadata": {
        "id": "icZM-pI0u0ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=.00001), \n",
        "                             loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                             metrics='accuracy')"
      ],
      "metadata": {
        "id": "uWGYdNkZROZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_model.summary()"
      ],
      "metadata": {
        "id": "hApspdAXQO5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51456eda-c8e5-4642-9ef3-1859c856e9af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " attention_masks_layer (InputLa  [(None, 512)]       0           []                               \n",
            " yer)                                                                                             \n",
            "                                                                                                  \n",
            " input_ids_layer (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " token_types_ids_layer (InputLa  [(None, 512)]       0           []                               \n",
            " yer)                                                                                             \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['attention_masks_layer[0][0]',  \n",
            "                                thPoolingAndCrossAt               'input_ids_layer[0][0]',        \n",
            "                                tentions(last_hidde               'token_types_ids_layer[0][0]']  \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 200)          153800      ['tf_bert_model[0][1]']          \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 5)            1005        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,465,077\n",
            "Trainable params: 108,465,077\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classification_model.fit([X_train_tokenized.input_ids, X_train_tokenized.token_type_ids, X_train_tokenized.attention_mask],\n",
        "                         y_train_tokenized,\n",
        "                         validation_data=([x_test_tokenized.input_ids, x_test_tokenized.token_type_ids, x_test_tokenized.attention_mask],\n",
        "                                          y_test_tokenized),\n",
        "                         epochs=3,\n",
        "                         batch_size=10)"
      ],
      "metadata": {
        "id": "rH-b3-t9sy6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45a3a959-bd9a-4e4c-e732-06e4b94823f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "8000/8000 [==============================] - 6012s 751ms/step - loss: 0.8818 - accuracy: 0.6093 - val_loss: 0.7539 - val_accuracy: 0.6694\n",
            "Epoch 2/3\n",
            "8000/8000 [==============================] - 6004s 751ms/step - loss: 0.7006 - accuracy: 0.6956 - val_loss: 0.7452 - val_accuracy: 0.6712\n",
            "Epoch 3/3\n",
            "8000/8000 [==============================] - 6005s 751ms/step - loss: 0.5896 - accuracy: 0.7472 - val_loss: 0.7750 - val_accuracy: 0.6747\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb37e3c6650>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = classification_model.predict([X_train_tokenized.input_ids, X_train_tokenized.token_type_ids, X_train_tokenized.attention_mask]#,\n",
        "                             #batch_size=1,\n",
        "                             #steps=80000)\n",
        ")"
      ],
      "metadata": {
        "id": "a9dAQbIv05k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "for pred in predictions:\n",
        "  preds.append(np.argmax(pred))\n",
        "\n",
        "np.unique(preds)"
      ],
      "metadata": {
        "id": "PIVaJKIwkx8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5971e1a0-50d7-41ef-c72c-a5c31356f970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR6As7bi4_hP",
        "outputId": "1fd6d63a-e330-4c37-d2a6-ccfe7feb1814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBN4_kD15xnx",
        "outputId": "08409d38-17c5-4a3c-b30f-26463ee6bdf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03626691, 0.05791741, 0.21747778, 0.62491596, 0.83137155],\n",
              "       [0.00969902, 0.01243679, 0.07472925, 0.89667344, 0.9892826 ],\n",
              "       [0.9854854 , 0.7612911 , 0.2053543 , 0.02133091, 0.02478397],\n",
              "       ...,\n",
              "       [0.97351855, 0.8721985 , 0.31855977, 0.01945437, 0.01431295],\n",
              "       [0.01162514, 0.36174682, 0.97523266, 0.78721195, 0.05085443],\n",
              "       [0.99668056, 0.58956647, 0.12467027, 0.01727189, 0.02502814]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.to_csv('BERT_Predictions_80k.csv', index=False)"
      ],
      "metadata": {
        "id": "hWjtQIl-a4Nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(np.sum(y_train['stars'][:num_train_examples] == 4)) / (len(y_train['stars'][:num_train_examples]))\n",
        "# Train 5s"
      ],
      "metadata": {
        "id": "6EM7uVryRZXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ec2e98-e600-4c81-9626-af6ebce20a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.199775"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(np.sum(y_test['stars'][:num_test_examples] == 4)) / (len(y_test['stars'][:num_test_examples]))\n",
        "# Test 5s (baseline)"
      ],
      "metadata": {
        "id": "2bORhgQYmO1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8455e671-bebe-4057-b6f1-7fe45e6cf649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2009"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(y_test['stars'][:num_test_examples] == 0)"
      ],
      "metadata": {
        "id": "sXIMc45rAfOV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a3dfc9d-fa89-477e-c658-41c6bca0a25e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4089"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y_test['stars'][:num_test_examples])"
      ],
      "metadata": {
        "id": "AkdzWBZIn3pH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b8191c-9bf2-4097-cd99-55c9c390ffac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problems to Address**\n",
        "* Need to tap into local resources (GPU) to speed processing - may need to specify in the model to utilize the GPU (and change runtime settings)\n",
        "* ***RESOLVED*** Accuracy could be quite low because of such a small data set\n",
        "* ***INCORPORATED*** We should get another dataset that is class-balanced\n",
        "* ***FIXED:*** Loss is way too low... need to investigate this, because it should start higher... first thought was learning rate was too high, but stayed the same at .01 Adam. Maybe this has more to do with the # of categories, which would exmplain the low accuracy and the low loss\n",
        "* ***DONE:*** Need to resolve the wrong number of categories predicted (should be 5, only returning 1)... I think I have the wrong number of neurons in the final prediction layers"
      ],
      "metadata": {
        "id": "qdCa2pH82Hmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZrF5M9oS9yjM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}