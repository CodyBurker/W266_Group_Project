{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodyBurker/W266_Group_Project/blob/CodyCNNBase/NonNeuralReferenceModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c60a99a",
      "metadata": {
        "id": "8c60a99a"
      },
      "source": [
        "Based on: https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d3d43e6b",
      "metadata": {
        "id": "d3d43e6b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/CodyBurker/W266_Group_Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LMKJsWAWDCN",
        "outputId": "29429c6f-8fd4-4be9-f6ad-3d9ff33cd1a6"
      },
      "id": "0LMKJsWAWDCN",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'W266_Group_Project' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4052af92",
      "metadata": {
        "id": "4052af92"
      },
      "outputs": [],
      "source": [
        "def read_in_data(path=\"W266_Group_Project/\"):\n",
        "    import pandas as pd\n",
        "    X_train = pd.read_csv(path + \"x_train_sampled_yelp_data.csv\")\n",
        "    y_train = pd.read_csv(path + \"y_train_sampled_yelp_data.csv\")\n",
        "    X_test = pd.read_csv(path + \"x_test_sampled_yelp_data.csv\")\n",
        "    y_test = pd.read_csv(path + \"y_test_sampled_yelp_data.csv\")\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6b7aac4d",
      "metadata": {
        "id": "6b7aac4d"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = read_in_data()\n",
        "y_train = np.array(y_train.stars.astype('int')) - 1\n",
        "y_test = np.array(y_test.stars.astype('int')) - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdev.com/sentiment-analysis-with-cnn-using-keras-c4debff57fc5?gi=708b4ef40e2f"
      ],
      "metadata": {
        "id": "ceOrQM3YXY7t"
      },
      "id": "ceOrQM3YXY7t"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode text and pad it."
      ],
      "metadata": {
        "id": "YuZGKY5XY3VG"
      },
      "id": "YuZGKY5XY3VG"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1tvRcs5RtiyX"
      },
      "id": "1tvRcs5RtiyX",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec: https://machinelearningknowledge.ai/word2vec-in-gensim-explained-for-creating-word-embedding-models-pretrained-and-custom/"
      ],
      "metadata": {
        "id": "soLNy3-ktjoi"
      },
      "id": "soLNy3-ktjoi"
    },
    {
      "cell_type": "code",
      "source": [
        "# from gensim.models import Word2Vec,KeyedVectors"
      ],
      "metadata": {
        "id": "3NwD8KzOtJ_f"
      },
      "id": "3NwD8KzOtJ_f",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "o90nvLmLXs_Q"
      },
      "id": "o90nvLmLXs_Q",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Non-Neural models"
      ],
      "metadata": {
        "id": "Sm4UErMI3xiw"
      },
      "id": "Sm4UErMI3xiw"
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocab is too big, try sklearn.feature_extraction.text.TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "matrix = CountVectorizer(max_features=5000)\n",
        "X_train_vectorized = matrix.fit_transform(X_train['text'])\n",
        "X_test_vectorized = matrix.transform(X_test['text'])\n"
      ],
      "metadata": {
        "id": "fmk1sT4J54rb"
      },
      "id": "fmk1sT4J54rb",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# tfid = TfidfVectorizer()\n",
        "# X_train_vectorized = tfid.fit_transform(X_train['text'])\n",
        "# X_test_vectorized = tfid.transform(X_test['text'])"
      ],
      "metadata": {
        "id": "v4Qr3wTk6DuP"
      },
      "id": "v4Qr3wTk6DuP",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train_vectorized.toarray(), y_train)\n",
        "gnb_preds = gnb.predict(X_test_vectorized.toarray())"
      ],
      "metadata": {
        "id": "vXsAjq9t3wuO"
      },
      "id": "vXsAjq9t3wuO",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "print(\"Gaussian Naive Bayes Accuracy:\",accuracy_score(y_test, gnb_preds))\n",
        "confusion_matrix(y_test, gnb_preds)"
      ],
      "metadata": {
        "id": "cfE749KS4kbv",
        "outputId": "5b2a6609-3322-4a26-8ab4-9d7804c2b680",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "cfE749KS4kbv",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gaussian Naive Bayes Accuracy: 0.5061\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1727,  404,  298,  120,  418],\n",
              "       [ 412,  294,  401,  195,  295],\n",
              "       [ 201,  219,  571,  583,  543],\n",
              "       [ 211,  209,  624, 1411, 1978],\n",
              "       [ 596,  217,  409, 1545, 6119]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
        "X_train_array = X_train_vectorized.toarray()\n",
        "rfc.fit(X_train_array, y_train)\n",
        "rfc_preds = rfc.predict(X_test_vectorized.toarray())\n",
        "\n",
        "accuracy_score(y_test, rfc_preds)"
      ],
      "metadata": {
        "id": "_2FeBAVX5A8B",
        "outputId": "8d49b7a7-0987-4e70-edef-ae1f803554e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_2FeBAVX5A8B",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4558"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Too slow to run :( \n",
        "# from sklearn.svm import SVC\n",
        "# svm_rbf = SVC(gamma=2, C=1)\n",
        "# svm_rbf.fit(X_train_array, y_train)\n",
        "# svm_preds = svm_rbf.predict(X_test_vectorized.toarray())\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# knn = KNeighborsClassifier(3)\n",
        "# knn.fit(X_train_array, y_train)\n",
        "# knn_preds = knn.predict(X_test_vectorized.toarray())\n",
        "# accuracy_score(y_test, knn_preds)\n"
      ],
      "metadata": {
        "id": "jSo7JzL5-tdT"
      },
      "id": "jSo7JzL5-tdT",
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_tensorflow2_latest_p37",
      "language": "python",
      "name": "conda_tensorflow2_latest_p37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "CodyCNNAnalysis2.ipynb",
      "provenance": [],
      "background_execution": "on",
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}