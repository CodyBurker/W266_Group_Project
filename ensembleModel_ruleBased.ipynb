{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ensembleModel_ruleBased.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VqxJi-AlH0RQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading in BERT confidences and predictions for training set 2\n",
        "train2_BERT_confidence = pd.read_csv(\"/content/drive/MyDrive/UC Berkeley MIDS/W266/t5_dataset/BERT_Confidence_Predictions_80k_Stage_2.csv\", sep = \",\", header=0)\n",
        "train2_BERT_preds = pd.read_csv(\"/content/drive/MyDrive/UC Berkeley MIDS/W266/t5_dataset/BERT_Predictions_80k_stage_2_1_to_5.csv\", sep = \",\", header=0)\n",
        "# Merging BERT predictions and confidences for training set 2\n",
        "train2_BERT = pd.merge(train2_BERT_preds,train2_BERT_confidence,on = [\"Unnamed: 0\",\"Unnamed: 0\"])"
      ],
      "metadata": {
        "id": "y40KJLm7luMW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading in BERT confidence and predictions test sets\n",
        "test_BERT_confidence = pd.read_csv(\"/content/drive/MyDrive/UC Berkeley MIDS/W266/t5_dataset/BERT_X_Test_Confidence_Predictions.csv\", sep = \",\", header=0)\n",
        "test_BERT_preds = pd.read_csv(\"/content/drive/MyDrive/UC Berkeley MIDS/W266/t5_dataset/BERT_X_Test_Predictions_1_to_5.csv\", sep = \",\", header=0)\n",
        "# Merging BERT predictions and confidences for test set\n",
        "test_BERT = pd.merge(test_BERT_preds,test_BERT_confidence,on = [\"Unnamed: 0\",\"Unnamed: 0\"])"
      ],
      "metadata": {
        "id": "9gQZ-59lyW-l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading in CNN confidences and predictions for training set 2\n",
        "train2_CNN = pd.read_csv(\"/content/drive/MyDrive/UC Berkeley MIDS/W266/t5_dataset/CNN_Confidence_x_train_stage_2_sampled_yelp_data.csv\", sep = \",\", header=0)\n",
        "train2_CNN_preds = pd.read_csv(\"/content/drive/MyDrive/UC Berkeley MIDS/W266/t5_dataset/CNN_Predictions.csv\", sep = \",\", header=0)"
      ],
      "metadata": {
        "id": "608NZWhuz8yG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading in CNN confidences and predictions for test set\n",
        "test_CNN = pd.read_csv(\"/content/drive/MyDrive/UC Berkeley MIDS/W266/t5_dataset/CNN_Confidence_x_test_sampled_yelp_data_NEW.csv\", sep = \",\", header=0)\n",
        "test_CNN_preds = pd.read_csv(\"/content/drive/MyDrive/UC Berkeley MIDS/W266/t5_dataset/X_test_predictions_1_to_5_CNN.csv\", sep = \",\", header=0)"
      ],
      "metadata": {
        "id": "LOEYdraw26I-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading in predictions for T5 for training set 2 and test set\n",
        "train2_t5 = pd.read_csv(\"/content/drive/MyDrive/UC Berkeley MIDS/W266/t5_dataset/t5_Predictions.csv\", sep = \",\", header=0),\n",
        "test_results = pd.read_csv(\"/content/drive/MyDrive/UC Berkeley MIDS/W266/t5_dataset/t5_Predictions_test20k.csv\", sep = \",\", header=0)"
      ],
      "metadata": {
        "id": "Wu581x5XJZ7u"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining all predictions and confidences for training set 2 as well as actual column\n",
        "train2Results = pd.DataFrame({'BERT_1': train2_BERT['BERT_1'],\n",
        "             'BERT_2': train2_BERT['BERT_2'],\n",
        "             'BERT_3': train2_BERT['BERT_3'],\n",
        "             'BERT_4': train2_BERT['BERT_4'],\n",
        "             'BERT_5': train2_BERT['BERT_5'],\n",
        "             'BERT_Predicted' : train2_BERT['0'],\n",
        "             'CNN_1': train2_CNN['CNN1'],\n",
        "             'CNN_2': train2_CNN['CNN2'],\n",
        "             'CNN_3': train2_CNN['CNN3'],\n",
        "             'CNN_4': train2_CNN['CNN4'],\n",
        "             'CNN_5': train2_CNN['CNN5'],\n",
        "             'CNN_Predicted' : train2_CNN_preds['CNN_predictions'],\n",
        "             'T5 Predicted':train2_t5['Predicted'],\n",
        "             'Actual' : train2_t5['Actual']\n",
        "})"
      ],
      "metadata": {
        "id": "iCe1ac9n_M6R"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining all predictions and confidences for test set as well as actual column\n",
        "allTestResults = pd.DataFrame({'BERT_1': test_BERT['BERT_1'],\n",
        "             'BERT_2': test_BERT['BERT_2'],\n",
        "             'BERT_3': test_BERT['BERT_3'],\n",
        "             'BERT_4': test_BERT['BERT_4'],\n",
        "             'BERT_5': test_BERT['BERT_5'],\n",
        "             'BERT_Predicted' : test_BERT['0'],\n",
        "             'CNN_1': test_CNN['CNN1'],\n",
        "             'CNN_2': test_CNN['CNN2'],\n",
        "             'CNN_3': test_CNN['CNN3'],\n",
        "             'CNN_4': test_CNN['CNN4'],\n",
        "             'CNN_5': test_CNN['CNN5'],\n",
        "             'CNN_Predicted' : test_CNN_preds['CNN_predictions'],\n",
        "             'T5 Predicted':test_results['Predicted'],\n",
        "             'Actual' : test_results['Actual']\n",
        "})"
      ],
      "metadata": {
        "id": "KUyU3LiRK2W3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rule based ensemble model with confidences\n",
        "def ruleBasedEnsemble(df):\n",
        "  count_allMatch = 0\n",
        "  count_twoMatches_BERT_CNN_Picked = 0\n",
        "  count_twoMatches_BERT_CNN_PickedT5 = 0\n",
        "  count_twoMatches_BERT_T5_Picked = 0\n",
        "  count_twoMatches_BERT_T5_PickedCNN = 0\n",
        "  count_twoMatches_T5_CNN_Picked = 0\n",
        "  count_twoMatches_T5_CNN_PickedBERT = 0\n",
        "  count_oneMatch_BERT = 0\n",
        "  count_oneMatch_CNN = 0\n",
        "  count_oneMatch_T5 = 0\n",
        "  for index, row in df.iterrows():\n",
        "    # Get max confidence for bert and cnn\n",
        "    bert_conf = max(row['BERT_1'],row['BERT_2'],row['BERT_3'],row['BERT_4'],row['BERT_5'])\n",
        "    cnn_conf = max(row['CNN_1'],row['CNN_2'],row['CNN_3'],row['CNN_4'],row['CNN_5'])\n",
        "    # Assumption: T5 confidence is 1\n",
        "\n",
        "    # See if BERT, CNN, and T5 predictions all match\n",
        "    if(row['BERT_Predicted']==row['CNN_Predicted']==row['T5 Predicted']):\n",
        "      df.loc[index, 'Final Predicted']=row['BERT_Predicted']\n",
        "      df.loc[index, 'Prediction used'] = \"All three match\"\n",
        "      count_allMatch = count_allMatch+1\n",
        "\n",
        "    # Else see if BERT and CNN predictions match\n",
        "    elif((row['BERT_Predicted']==row['CNN_Predicted'])):\n",
        "      if((bert_conf+cnn_conf)>=1):\n",
        "        df.loc[index, 'Final Predicted']=row['BERT_Predicted']\n",
        "        df.loc[index, 'Prediction used'] = \"BERT & CNN\"\n",
        "        count_twoMatches_BERT_CNN_Picked = count_twoMatches_BERT_CNN_Picked+1\n",
        "      else:\n",
        "        # Revert to T5 prediction if BERT + CNN confidences are not greater than or equal to 1\n",
        "        df.loc[index,'Final Predicted']=row['T5 Predicted']\n",
        "        df.loc[index, 'Prediction used'] = \"BERT & CNN Reverted to T5\"\n",
        "        count_twoMatches_BERT_CNN_PickedT5=count_twoMatches_BERT_CNN_PickedT5+1\n",
        "\n",
        "    # Else see if BERT and T5 predictions match\n",
        "    elif((row['BERT_Predicted']==row['T5 Predicted'])):\n",
        "      if((bert_conf+1)/2 >=cnn_conf):\n",
        "        df.loc[index, 'Final Predicted']=row['BERT_Predicted']\n",
        "        df.loc[index, 'Prediction used'] = \"BERT & T5\"\n",
        "        count_twoMatches_BERT_T5_Picked = count_twoMatches_BERT_T5_Picked+1\n",
        "      else:\n",
        "        # Revert to CNN if average confidence of BERT and T5 is less than CNN confidence\n",
        "        df.loc[index, 'Final Predicted']=row['CNN_Predicted']\n",
        "        df.loc[index, 'Prediction used'] = \"BERT & T5 Reverted to CNN\"\n",
        "        count_twoMatches_BERT_T5_PickedCNN = count_twoMatches_BERT_T5_PickedCNN+1\n",
        "\n",
        "    # Else see if CNN and T5 predictions match\n",
        "    elif((row['CNN_Predicted']==row['T5 Predicted'])):\n",
        "      # Revert to BERT if average confidence of CNN and T5 is less than BERT confidence\n",
        "      if(((cnn_conf+1)/2 <=bert_conf)):\n",
        "        df.loc[index, 'Final Predicted']=row['BERT_Predicted']\n",
        "        df.loc[index, 'Prediction used'] = \"CNN & T5 Reverted to BERT\"\n",
        "        count_twoMatches_T5_CNN_PickedBERT = count_twoMatches_T5_CNN_PickedBERT+1\n",
        "\n",
        "      else:\n",
        "        df.loc[index, 'Final Predicted']=row['CNN_Predicted']\n",
        "        df.loc[index, 'Prediction used'] = \"CNN & T5\"\n",
        "        count_twoMatches_T5_CNN_Picked = count_twoMatches_T5_CNN_Picked+1\n",
        "        \n",
        "    else:\n",
        "      # Else use BERT prediction if BERT confidence is greater than or equal to 55%\n",
        "      if(bert_conf>=0.55):\n",
        "        df.loc[index,'Final Predicted']=row['BERT_Predicted']\n",
        "        df.loc[index, 'Prediction used'] = \"BERT\"\n",
        "        count_oneMatch_BERT=count_oneMatch_BERT+1\n",
        "\n",
        "      # Else use CNN prediction if CNN confidence is greater than or equal to 45%\n",
        "      elif(cnn_conf>=0.45):\n",
        "        df.loc[index,'Final Predicted']=row['CNN_Predicted']\n",
        "        df.loc[index, 'Prediction used'] = \"CNN\"\n",
        "        count_oneMatch_CNN = count_oneMatch_CNN+1\n",
        "\n",
        "      # Else use T5 prediction\n",
        "      else:\n",
        "        df.loc[index,'Final Predicted']=row['T5 Predicted']\n",
        "        df.loc[index, 'Prediction used'] = \"T5\"\n",
        "        count_oneMatch_T5=count_oneMatch_T5+1\n",
        "\n",
        "  # Print out breakdown and ensure there are no unaccounted for predictions\n",
        "  remainingRows = df.shape[0]-count_allMatch-count_twoMatches_BERT_CNN_Picked-count_twoMatches_BERT_CNN_PickedT5-count_twoMatches_BERT_T5_Picked-count_twoMatches_BERT_T5_PickedCNN-count_twoMatches_T5_CNN_Picked-count_twoMatches_T5_CNN_PickedBERT-count_oneMatch_BERT-count_oneMatch_CNN-count_oneMatch_T5\n",
        "  print(\"All three match: \", count_allMatch)\n",
        "  print(\"Two matches - BERT & CNN: \", count_twoMatches_BERT_CNN_Picked)\n",
        "  print(\"Two matches - BERT & CNN Revert to T5: \", count_twoMatches_BERT_CNN_PickedT5)\n",
        "  print(\"Two matches - BERT & T5: \", count_twoMatches_BERT_T5_Picked)\n",
        "  print(\"Two matches - BERT & T5 Revert to CNN: \", count_twoMatches_BERT_T5_PickedCNN)\n",
        "  print(\"Two matches - CNN & T5: \", count_twoMatches_T5_CNN_Picked)\n",
        "  print(\"Two matches - CNN & T5 Revert to BERT: \", count_twoMatches_T5_CNN_PickedBERT)\n",
        "  print(\"One match - BERT: \", count_oneMatch_BERT)\n",
        "  print(\"One match - CNN: \", count_oneMatch_CNN)\n",
        "  print(\"One match - T5: \", count_oneMatch_T5)\n",
        "  print(\"Remaining: \", remainingRows)\n",
        "  \n",
        "  return df"
      ],
      "metadata": {
        "id": "qItdHDZfFfFY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run ensemble model on training 2 set\n",
        "train2Results_ensemble = ruleBasedEnsemble(train2Results)\n",
        "# Get accuracy\n",
        "labels = train2Results_ensemble['Actual']\n",
        "preds = train2Results_ensemble['Final Predicted']\n",
        "matches = sum([1 if label == pred else 0 for label, pred in zip(labels, preds)])\n",
        "print(\"Val accuracy: \", matches/80000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DayGvyc4GDbH",
        "outputId": "b7367204-0473-4d4c-9b77-043e75bae743"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All three match:  49451\n",
            "Two matches - BERT & CNN:  10442\n",
            "Two matches - BERT & CNN Revert to T5:  30\n",
            "Two matches - BERT & T5:  8996\n",
            "Two matches - BERT & T5 Revert to CNN:  12\n",
            "Two matches - CNN & T5:  741\n",
            "Two matches - CNN & T5 Revert to BERT:  6799\n",
            "One match - BERT:  3485\n",
            "One match - CNN:  23\n",
            "One match - T5:  21\n",
            "Remaining:  0\n",
            "Val accuracy:  0.7225375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Results of fine-tuning ensemble model on training 2 set\n",
        "# 71.01% train with BERT>= 0.85 and CNN >=0.5\n",
        "# 71.15% train with BERT >= 0.8 and CNN >=0.5\n",
        "# 71.2% train with BERT >= 0.75 and CNN >=0.5\n",
        "# 71.23% train with BERT >= 0.7 and CNN >=0.5\n",
        "# 71.24% train with BERT >= 0.65 and CNN >=0.5\n",
        "# 71.25% train with BERT >= 0.6 and CNN >=0.5\n",
        "# 71.25% train with BERT >= 0.55 and CNN >=0.5\n",
        "# 71.25% train with BERT >= 0.55 and CNN >=0.55\n",
        "# 71.25% train with BERT >= 0.55 and CNN >=0.45\n",
        "\n",
        "# Ensemble model with reverts \n",
        "# 72.25%"
      ],
      "metadata": {
        "id": "zDpQimIhG2oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at the groupings of the incorrect results\n",
        "incorrectResults = train2Results_ensemble[train2Results_ensemble['Final Predicted']!=train2Results_ensemble['Actual']]\n",
        "incorrectResults.groupby('Prediction used').size()"
      ],
      "metadata": {
        "id": "SeyIpqKwYbhW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67476952-214d-4f47-d36d-60795ea830fb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Prediction used\n",
              "All three match              8962\n",
              "BERT                         1850\n",
              "BERT & CNN                   3733\n",
              "BERT & CNN Reverted to T5      26\n",
              "BERT & T5                    3724\n",
              "BERT & T5 Reverted to CNN      11\n",
              "CNN                            22\n",
              "CNN & T5                      506\n",
              "CNN & T5 Reverted to BERT    3347\n",
              "T5                             16\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at validation accuracy for binned predictions (stars 1-2 binned and stars 4-5 binned) on train set 2\n",
        "train2Results_ensemble['Final Predicted Binned'] = train2Results_ensemble['Final Predicted'].apply(lambda x: 1.0 if ((x == 1.0) | (x == 2.0)) else (5.0 if ((x == 4.0) | (x== 5.0)) else 3.0))\n",
        "train2Results_ensemble['Actual Binned'] = train2Results_ensemble['Actual'].apply(lambda x: 1.0 if ((x == 1.0) | (x == 2.0)) else (5.0 if ((x == 4.0) | (x==5.0)) else 3.0))\n",
        "labels = train2Results_ensemble['Actual Binned']\n",
        "preds = train2Results_ensemble['Final Predicted Binned']\n",
        "matches = sum([1 if label == pred else 0 for label, pred in zip(labels, preds)])\n",
        "print(\"Val accuracy: \", matches/80000)"
      ],
      "metadata": {
        "id": "BVYyH_WMhqW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93f128f-053a-4cb0-99c0-13999e21101a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val accuracy:  0.8936375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running ensemble model on test data\n",
        "testResults_ensemble = ruleBasedEnsemble(allTestResults)\n",
        "labels = testResults_ensemble['Actual']\n",
        "preds = testResults_ensemble['Final Predicted']\n",
        "matches = sum([1 if label == pred else 0 for label, pred in zip(labels, preds)])\n",
        "print(\"Val accuracy: \", matches/20000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFtxJoKZGin5",
        "outputId": "2ecac947-1af3-4d92-e64e-3a30b625230b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All three match:  12200\n",
            "Two matches - BERT & CNN:  2592\n",
            "Two matches - BERT & CNN Revert to T5:  2\n",
            "Two matches - BERT & T5:  2254\n",
            "Two matches - BERT & T5 Revert to CNN:  0\n",
            "Two matches - CNN & T5:  88\n",
            "Two matches - CNN & T5 Revert to BERT:  1935\n",
            "One match - BERT:  928\n",
            "One match - CNN:  0\n",
            "One match - T5:  1\n",
            "Remaining:  0\n",
            "Val accuracy:  0.72515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at validation accuracy for binned predictions (stars 1-2 binned and stars 4-5 binned) on test set\n",
        "testResults_ensemble['Final Predicted Binned'] = testResults_ensemble['Final Predicted'].apply(lambda x: 1.0 if ((x == 1.0) | (x == 2.0)) else (5.0 if ((x == 4.0) | (x== 5.0)) else 3.0))\n",
        "testResults_ensemble['Actual Binned'] = testResults_ensemble['Actual'].apply(lambda x: 1.0 if ((x == 1.0) | (x == 2.0)) else (5.0 if ((x == 4.0) | (x==5.0)) else 3.0))\n",
        "labels = testResults_ensemble['Actual Binned']\n",
        "preds = testResults_ensemble['Final Predicted Binned']\n",
        "matches = sum([1 if label == pred else 0 for label, pred in zip(labels, preds)])\n",
        "print(\"Val accuracy: \", matches/20000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pnt51K92q2yX",
        "outputId": "3dd8e613-0d46-405d-b392-9d34103d52c1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val accuracy:  0.89505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at validation accuracy for binned predictions (stars 1-2 binned and stars 4-5 binned) on test set for baseline models\n",
        "testResults_ensemble['BERT Predicted Binned'] = testResults_ensemble['BERT_Predicted'].apply(lambda x: 1.0 if ((x == 1.0) | (x == 2.0)) else (5.0 if ((x == 4.0) | (x== 5.0)) else 3.0))\n",
        "preds = testResults_ensemble['BERT Predicted Binned']\n",
        "matches = sum([1 if label == pred else 0 for label, pred in zip(labels, preds)])\n",
        "print(\"BERT Binned Val accuracy: \", matches/20000)\n",
        "\n",
        "testResults_ensemble['CNN Predicted Binned'] = testResults_ensemble['CNN_Predicted'].apply(lambda x: 1.0 if ((x == 1.0) | (x == 2.0)) else (5.0 if ((x == 4.0) | (x== 5.0)) else 3.0))\n",
        "preds = testResults_ensemble['CNN Predicted Binned']\n",
        "matches = sum([1 if label == pred else 0 for label, pred in zip(labels, preds)])\n",
        "print(\"CNN Binned Val accuracy: \", matches/20000)\n",
        "\n",
        "testResults_ensemble['T5 Predicted Binned'] = testResults_ensemble['T5 Predicted'].apply(lambda x: 1.0 if ((x == 1.0) | (x == 2.0)) else (5.0 if ((x == 4.0) | (x== 5.0)) else 3.0))\n",
        "preds = testResults_ensemble['T5 Predicted Binned']\n",
        "matches = sum([1 if label == pred else 0 for label, pred in zip(labels, preds)])\n",
        "print(\"T5 Binned Val accuracy: \", matches/20000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HjAUuQ6rCD3",
        "outputId": "ff690ba7-b24e-42d4-bd2e-b7bdee8ca1c2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Binned Val accuracy:  0.89525\n",
            "CNN Binned Val accuracy:  0.8557\n",
            "T5 Binned Val accuracy:  0.8468\n"
          ]
        }
      ]
    }
  ]
}